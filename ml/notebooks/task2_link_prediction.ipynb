{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704b328f-af15-49fc-a189-f7f6d91e3438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n",
      "Configuration charg√©e\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx, train_test_split_edges, negative_sampling\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "print(\"Imports OK\")\n",
    "\n",
    "# %% Charger configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "CACHE_PATH = config['graph']['cache_path']\n",
    "PARTITION_PATH = \"../results/communities/louvain_partition.pkl\"\n",
    "MODEL_OUTPUT = config['graph']['MODEL_PATH']\n",
    "\n",
    "print(\"Configuration charg√©e\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a604213-e2f8-45e2-b475-fd816a09912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphe charg√© : 10363 n≈ìuds, 300869 ar√™tes\n",
      "Communaut√©s charg√©es : 45\n"
     ]
    }
   ],
   "source": [
    "# %% Chargement du graphe\n",
    "with open(CACHE_PATH, 'rb') as f:\n",
    "    G_nx = pickle.load(f)\n",
    "\n",
    "print(f\"Graphe charg√© : {G_nx.number_of_nodes()} n≈ìuds, {G_nx.number_of_edges()} ar√™tes\")\n",
    "\n",
    "# Charger Louvain\n",
    "with open(PARTITION_PATH, \"rb\") as f:\n",
    "    partition = pickle.load(f)\n",
    "\n",
    "print(f\"Communaut√©s charg√©es : {len(set(partition.values()))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66716c70-74f3-4f71-87ea-16a5d20924b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Conversion NetworkX ‚Üí PyTorch Geometric (avec remapping)...\n",
      "\n",
      "‚úì Mapping cr√©√© pour 10363 n≈ìuds\n",
      "  Exemple: n≈ìud 50562026 ‚Üí index 0\n",
      "  Exemple: n≈ìud 2115828967 ‚Üí index 10362\n",
      "\n",
      "‚úì edge_index cr√©√©: torch.Size([2, 300869])\n",
      "  Min index: 0\n",
      "  Max index: 10362\n",
      "  Attendu max: 10362\n",
      "\n",
      "Calcul des features...\n",
      "‚úì Features cr√©√©es: torch.Size([10363, 3])\n",
      "\n",
      "============================================================\n",
      "üìä OBJET DATA CR√â√â ET V√âRIFI√â\n",
      "============================================================\n",
      "  N≈ìuds: 10363\n",
      "  Ar√™tes: 300869\n",
      "  Features: torch.Size([10363, 3])\n",
      "  edge_index range: [0, 10362]\n",
      "  Communaut√©s: 45\n",
      "============================================================\n",
      "\n",
      "‚úÖ Toutes les v√©rifications pass√©es - Pr√™t pour le split!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "print(\"üîÑ Conversion NetworkX ‚Üí PyTorch Geometric (avec remapping)...\\n\")\n",
    "\n",
    "# ===== √âTAPE 1 : CR√âER UN MAPPING CONTINU =====\n",
    "node_list = list(G_nx.nodes())\n",
    "node_to_idx = {node: idx for idx, node in enumerate(node_list)}\n",
    "print(f\"‚úì Mapping cr√©√© pour {len(node_list)} n≈ìuds\")\n",
    "print(f\"  Exemple: n≈ìud {node_list[0]} ‚Üí index 0\")\n",
    "print(f\"  Exemple: n≈ìud {node_list[-1]} ‚Üí index {len(node_list)-1}\")\n",
    "\n",
    "# ===== √âTAPE 2 : CONVERTIR LES AR√äTES =====\n",
    "edges_remapped = [\n",
    "    (node_to_idx[u], node_to_idx[v]) \n",
    "    for u, v in G_nx.edges()\n",
    "]\n",
    "edge_index = torch.tensor(edges_remapped, dtype=torch.long).t().contiguous()\n",
    "\n",
    "print(f\"\\n‚úì edge_index cr√©√©: {edge_index.shape}\")\n",
    "print(f\"  Min index: {edge_index.min().item()}\")\n",
    "print(f\"  Max index: {edge_index.max().item()}\")\n",
    "print(f\"  Attendu max: {len(node_list) - 1}\")\n",
    "\n",
    "# V√©rification critique\n",
    "assert edge_index.max().item() < len(node_list), \\\n",
    "    f\"‚ùå ERREUR: edge_index contient {edge_index.max().item()} mais seulement {len(node_list)} n≈ìuds!\"\n",
    "assert edge_index.min().item() >= 0, \\\n",
    "    f\"‚ùå ERREUR: edge_index contient des indices n√©gatifs!\"\n",
    "\n",
    "# ===== √âTAPE 3 : FEATURES (avec remapping) =====\n",
    "print(\"\\nCalcul des features...\")\n",
    "deg = dict(G_nx.degree())\n",
    "pagerank = nx.pagerank(G_nx, max_iter=50)\n",
    "clustering = nx.clustering(G_nx)\n",
    "\n",
    "x = torch.tensor([\n",
    "    [deg[node], pagerank[node], clustering[node]] \n",
    "    for node in node_list  # ‚Üê Utiliser node_list dans l'ordre\n",
    "], dtype=torch.float)\n",
    "\n",
    "print(f\"‚úì Features cr√©√©es: {x.shape}\")\n",
    "\n",
    "# ===== √âTAPE 4 : COMMUNAUT√âS (avec remapping) =====\n",
    "community = torch.tensor(\n",
    "    [partition.get(node, -1) for node in node_list],\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "missing = (community == -1).sum().item()\n",
    "if missing > 0:\n",
    "    print(f\"‚ö†Ô∏è {missing} n≈ìuds sans communaut√© (assign√©s √† -1)\")\n",
    "\n",
    "# ===== √âTAPE 5 : CR√âER L'OBJET DATA =====\n",
    "data = Data(\n",
    "    x=x,\n",
    "    edge_index=edge_index,\n",
    "    community=community,\n",
    "    num_nodes=len(node_list)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä OBJET DATA CR√â√â ET V√âRIFI√â\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  N≈ìuds: {data.num_nodes}\")\n",
    "print(f\"  Ar√™tes: {data.edge_index.shape[1]}\")\n",
    "print(f\"  Features: {data.x.shape}\")\n",
    "print(f\"  edge_index range: [{edge_index.min().item()}, {edge_index.max().item()}]\")\n",
    "print(f\"  Communaut√©s: {community.max().item() + 1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== V√âRIFICATION FINALE =====\n",
    "assert data.edge_index.max() < data.num_nodes, \"‚ùå Indices hors limites!\"\n",
    "print(\"\\n‚úÖ Toutes les v√©rifications pass√©es - Pr√™t pour le split!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09cc3943-8314-454d-a128-6195b2c0dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant split - edge_index: torch.Size([2, 300869])\n",
      "\n",
      "‚úÖ Train/val/test split OK\n",
      "  Train edges: 511480\n",
      "  Val edges: 30086\n",
      "  Test edges: 60172\n",
      "  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %% Split edges (VERSION CORRIG√âE)\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "print(f\"Avant split - edge_index: {data.edge_index.shape}\")\n",
    "\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1.0\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "print(\"\\n‚úÖ Train/val/test split OK\")\n",
    "print(f\"  Train edges: {train_data.edge_index.size(1)}\")\n",
    "print(f\"  Val edges: {val_data.edge_label_index.size(1)}\")      # ‚Üê CORRIG√â ICI\n",
    "print(f\"  Test edges: {test_data.edge_label_index.size(1)}\")    # ‚Üê CORRIG√â ICI\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c33c25-dcb0-48fc-8203-18f08cd7eab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®les cr√©√©s\n",
      "  GNN params: 17,344\n",
      "  Edge predictor params: 129\n"
     ]
    }
   ],
   "source": [
    "# %% Model d√©finition (VERSION AM√âLIOR√âE)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)  # ‚Üê Dropout ajout√©\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class EdgePredictor(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        # Option 1 : Concat√©nation (votre version)\n",
    "        self.lin = nn.Linear(embedding_dim * 2, 1)\n",
    "    \n",
    "    def forward(self, z, edge_index):\n",
    "        src = z[edge_index[0]]\n",
    "        dst = z[edge_index[1]]\n",
    "        # Concat√©nation\n",
    "        out = torch.cat([src, dst], dim=1)\n",
    "        return torch.sigmoid(self.lin(out)).squeeze()  # ‚Üê squeeze() ajout√©\n",
    "\n",
    "# OU version alternative avec produit scalaire (plus simple et souvent meilleure)\n",
    "class EdgePredictorDot(nn.Module):\n",
    "    \"\"\"Pr√©diction par produit scalaire (recommand√©)\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, z, edge_index):\n",
    "        src = z[edge_index[0]]\n",
    "        dst = z[edge_index[1]]\n",
    "        # Produit scalaire\n",
    "        return torch.sigmoid((src * dst).sum(dim=-1))\n",
    "\n",
    "# Initialisation\n",
    "embedding_dim = 64\n",
    "gnn = GraphSAGE(\n",
    "    in_channels=train_data.x.size(1),  # 3 features\n",
    "    hidden_channels=128,\n",
    "    out_channels=embedding_dim,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "edge_predictor = EdgePredictor(embedding_dim).to(device)\n",
    "# OU\n",
    "# edge_predictor = EdgePredictorDot().to(device)  # Version plus simple\n",
    "\n",
    "print(\"‚úÖ Mod√®les cr√©√©s\")\n",
    "print(f\"  GNN params: {sum(p.numel() for p in gnn.parameters()):,}\")\n",
    "print(f\"  Edge predictor params: {sum(p.numel() for p in edge_predictor.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d317f60b-3f1f-46b7-a5c6-10a832dd10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®les initialis√©s\n",
      "  Encoder: 17,344 params\n",
      "  Predictor: 129 params\n"
     ]
    }
   ],
   "source": [
    "# %% Init model\n",
    "encoder = GraphSAGE(\n",
    "    in_channels=train_data.x.size(1),  # ‚Üê Utiliser train_data, pas data\n",
    "    hidden_channels=128,\n",
    "    out_channels=64,\n",
    "    dropout=0.5\n",
    ").to(device)\n",
    "\n",
    "predictor = EdgePredictor(64).to(device)  # ‚Üê Adapter √† out_channels\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(predictor.parameters()),\n",
    "    lr=0.01,\n",
    "    weight_decay=5e-4  # ‚Üê R√©gularisation\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()  # Loss pour classification binaire\n",
    "\n",
    "print(\"‚úÖ Mod√®les initialis√©s\")\n",
    "print(f\"  Encoder: {sum(p.numel() for p in encoder.parameters()):,} params\")\n",
    "print(f\"  Predictor: {sum(p.numel() for p in predictor.parameters()):,} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94883141-e824-47db-bc2c-0f935c11f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analyse de la distribution des degr√©s...\n",
      "\n",
      "Distribution des degr√©s:\n",
      "   M√©diane (p50): 11\n",
      "   p90: 278\n",
      "   p95 (seuil hubs): 312\n",
      "   Max: 568\n",
      "\n",
      "Cat√©gorisation:\n",
      "   Low (‚â§p50): 5263 n≈ìuds\n",
      "   Mid (p50-p90): 4277 n≈ìuds\n",
      "   High (p90-p95): 314 n≈ìuds\n",
      "   Extreme (>p95): 509 n≈ìuds\n",
      "\n",
      "‚ö†Ô∏è Les extreme hubs seront EXCLUS du negative sampling\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Analyse de la distribution des degr√©s...\\n\")\n",
    "\n",
    "# Calculer les degr√©s\n",
    "node_degrees = dict(G_nx.degree())\n",
    "degrees_array = np.array([node_degrees[node] for node in node_list])\n",
    "\n",
    "# Calculer percentiles\n",
    "degree_p50 = np.percentile(degrees_array, 50)\n",
    "degree_p90 = np.percentile(degrees_array, 90)\n",
    "degree_p95 = np.percentile(degrees_array, 95)\n",
    "\n",
    "print(f\"Distribution des degr√©s:\")\n",
    "print(f\"   M√©diane (p50): {degree_p50:.0f}\")\n",
    "print(f\"   p90: {degree_p90:.0f}\")\n",
    "print(f\"   p95 (seuil hubs): {degree_p95:.0f}\")\n",
    "print(f\"   Max: {degrees_array.max():.0f}\")\n",
    "\n",
    "# Identifier les n≈ìuds par cat√©gorie\n",
    "low_degree_mask = degrees_array <= degree_p50\n",
    "mid_degree_mask = (degrees_array > degree_p50) & (degrees_array <= degree_p90)\n",
    "high_degree_mask = (degrees_array > degree_p90) & (degrees_array <= degree_p95)\n",
    "extreme_hub_mask = degrees_array > degree_p95\n",
    "\n",
    "low_nodes = np.where(low_degree_mask)[0]\n",
    "mid_nodes = np.where(mid_degree_mask)[0]\n",
    "high_nodes = np.where(high_degree_mask)[0]\n",
    "extreme_hubs = np.where(extreme_hub_mask)[0]\n",
    "\n",
    "print(f\"\\nCat√©gorisation:\")\n",
    "print(f\"   Low (‚â§p50): {len(low_nodes)} n≈ìuds\")\n",
    "print(f\"   Mid (p50-p90): {len(mid_nodes)} n≈ìuds\")\n",
    "print(f\"   High (p90-p95): {len(high_nodes)} n≈ìuds\")\n",
    "print(f\"   Extreme (>p95): {len(extreme_hubs)} n≈ìuds\")\n",
    "print(f\"\\n‚ö†Ô∏è Les extreme hubs seront EXCLUS du negative sampling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7d45c3-8f72-4065-858b-aa91680dbbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction d'entra√Ænement cr√©√©e (avec stratification anti-hub)\n"
     ]
    }
   ],
   "source": [
    "def train_with_stratified_negatives():\n",
    "    \"\"\"Training avec negative sampling stratifi√© pour √©viter biais hub\"\"\"\n",
    "    encoder.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Encoder le graphe\n",
    "    z = encoder(train_data.x, train_data.edge_index)\n",
    "    \n",
    "    # ===== NEGATIVE SAMPLING STRATIFI√â =====\n",
    "    num_pos = train_data.edge_label_index[:, train_data.edge_label == 1].size(1)\n",
    "    \n",
    "    # Ratio: 50% low, 30% mid, 20% high (pas d'extreme hubs)\n",
    "    num_low = int(num_pos * 0.5)\n",
    "    num_mid = int(num_pos * 0.3)\n",
    "    num_high = int(num_pos * 0.2)\n",
    "    \n",
    "    # Sources al√©atoires\n",
    "    src_low = torch.randint(0, train_data.num_nodes, (num_low,), device=device)\n",
    "    src_mid = torch.randint(0, train_data.num_nodes, (num_mid,), device=device)\n",
    "    src_high = torch.randint(0, train_data.num_nodes, (num_high,), device=device)\n",
    "    \n",
    "    # Targets stratifi√©s (SANS extreme hubs)\n",
    "    dst_low = torch.from_numpy(np.random.choice(low_nodes, num_low, replace=True)).to(device)\n",
    "    dst_mid = torch.from_numpy(np.random.choice(mid_nodes, num_mid, replace=True)).to(device)\n",
    "    dst_high = torch.from_numpy(np.random.choice(high_nodes, num_high, replace=True)).to(device)\n",
    "    \n",
    "    # Cr√©er edge_index n√©gatif\n",
    "    neg_src = torch.cat([src_low, src_mid, src_high])\n",
    "    neg_dst = torch.cat([dst_low, dst_mid, dst_high])\n",
    "    neg_edge_index = torch.stack([neg_src, neg_dst])\n",
    "    \n",
    "    # ===== PR√âDICTIONS =====\n",
    "    pos_edge_index = train_data.edge_label_index[:, train_data.edge_label == 1]\n",
    "    pos_pred = predictor(z, pos_edge_index)\n",
    "    neg_pred = predictor(z, neg_edge_index)\n",
    "    \n",
    "    # ===== LOSS AVEC POND√âRATION =====\n",
    "    # P√©naliser plus les erreurs sur low-degree nodes\n",
    "    pos_target_degrees = degrees_array[pos_edge_index[1].cpu().numpy()]\n",
    "    pos_weights = torch.from_numpy(1.0 / np.log(pos_target_degrees + 2)).float().to(device)\n",
    "    pos_weights = pos_weights / pos_weights.sum() * len(pos_weights)\n",
    "    \n",
    "    pos_loss = F.binary_cross_entropy(pos_pred, torch.ones_like(pos_pred), weight=pos_weights)\n",
    "    neg_loss = F.binary_cross_entropy(neg_pred, torch.zeros_like(neg_pred))\n",
    "    \n",
    "    loss = pos_loss + neg_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n",
    "    torch.nn.utils.clip_grad_norm_(predictor.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), pos_pred.mean().item(), neg_pred.mean().item()\n",
    "\n",
    "print(\"‚úÖ Fonction d'entra√Ænement cr√©√©e (avec stratification anti-hub)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee14a353-3042-40e1-bcf9-79b57fe1a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction de test cr√©√©e (avec analyse par degr√©)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_with_degree_analysis(data_split):\n",
    "    \"\"\"Test avec analyse par cat√©gorie de degr√©\"\"\"\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "    \n",
    "    z = encoder(data_split.x, train_data.edge_index)\n",
    "    pred = predictor(z, data_split.edge_label_index)\n",
    "    \n",
    "    pred_cpu = pred.cpu().numpy()\n",
    "    label_cpu = data_split.edge_label.cpu().numpy()\n",
    "    \n",
    "    # M√©triques globales\n",
    "    auc = roc_auc_score(label_cpu, pred_cpu)\n",
    "    pred_binary = (pred > 0.5).cpu().numpy()\n",
    "    acc = (pred_binary == label_cpu).mean()\n",
    "    \n",
    "    # Analyse par degr√©\n",
    "    target_degrees = degrees_array[data_split.edge_label_index[1].cpu().numpy()]\n",
    "    \n",
    "    low_mask = target_degrees <= degree_p50\n",
    "    high_mask = target_degrees > degree_p90\n",
    "    \n",
    "    auc_low = roc_auc_score(label_cpu[low_mask], pred_cpu[low_mask]) if low_mask.sum() > 10 else None\n",
    "    auc_high = roc_auc_score(label_cpu[high_mask], pred_cpu[high_mask]) if high_mask.sum() > 10 else None\n",
    "    \n",
    "    return auc, acc, auc_low, auc_high\n",
    "\n",
    "print(\"‚úÖ Fonction de test cr√©√©e (avec analyse par degr√©)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ddeeb6f-c698-4880-9255-6a44b2c1f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©but de l'entra√Ænement (anti-hub bias)...\n",
      "\n",
      "Epoch 005 | Loss: 75.5039 | Val AUC: 0.2366 | Pos: 0.000 | Neg: 0.001\n",
      "           | AUC Low-deg: 0.6727 | AUC High-deg: 0.0748\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 010 | Loss: 29.2397 | Val AUC: 0.8332 | Pos: 0.856 | Neg: 0.610\n",
      "           | AUC Low-deg: 0.6811 | AUC High-deg: 0.3993\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 015 | Loss: 29.4014 | Val AUC: 0.8381 | Pos: 0.938 | Neg: 0.510\n",
      "           | AUC Low-deg: 0.6818 | AUC High-deg: 0.5067\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 020 | Loss: 27.1053 | Val AUC: 0.8724 | Pos: 0.965 | Neg: 0.684\n",
      "           | AUC Low-deg: 0.6756 | AUC High-deg: 0.5000\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 025 | Loss: 13.2318 | Val AUC: 0.8231 | Pos: 0.221 | Neg: 0.337\n",
      "           | AUC Low-deg: 0.4189 | AUC High-deg: 0.9737\n",
      "Epoch 030 | Loss: 10.5426 | Val AUC: 0.2755 | Pos: 0.409 | Neg: 0.268\n",
      "           | AUC Low-deg: 0.4965 | AUC High-deg: 0.9630\n",
      "Epoch 035 | Loss: 13.0520 | Val AUC: 0.8511 | Pos: 0.936 | Neg: 0.478\n",
      "           | AUC Low-deg: 0.4774 | AUC High-deg: 0.9784\n",
      "Epoch 040 | Loss: 5.4659 | Val AUC: 0.8664 | Pos: 0.927 | Neg: 0.660\n",
      "           | AUC Low-deg: 0.5134 | AUC High-deg: 0.6225\n",
      "Epoch 045 | Loss: 1.4521 | Val AUC: 0.8783 | Pos: 0.553 | Neg: 0.387\n",
      "           | AUC Low-deg: 0.4788 | AUC High-deg: 0.9749\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 050 | Loss: 1.8697 | Val AUC: 0.8612 | Pos: 0.289 | Neg: 0.342\n",
      "           | AUC Low-deg: 0.6581 | AUC High-deg: 0.3876\n",
      "Epoch 055 | Loss: 1.8915 | Val AUC: 0.8232 | Pos: 0.249 | Neg: 0.283\n",
      "           | AUC Low-deg: 0.5170 | AUC High-deg: 0.9692\n",
      "Epoch 060 | Loss: 1.1737 | Val AUC: 0.8717 | Pos: 0.614 | Neg: 0.414\n",
      "           | AUC Low-deg: 0.5168 | AUC High-deg: 0.9675\n",
      "Epoch 065 | Loss: 1.1619 | Val AUC: 0.8717 | Pos: 0.615 | Neg: 0.404\n",
      "           | AUC Low-deg: 0.5064 | AUC High-deg: 0.9719\n",
      "Epoch 070 | Loss: 1.1071 | Val AUC: 0.8709 | Pos: 0.690 | Neg: 0.425\n",
      "           | AUC Low-deg: 0.4666 | AUC High-deg: 0.9699\n",
      "Epoch 075 | Loss: 1.0698 | Val AUC: 0.8879 | Pos: 0.736 | Neg: 0.402\n",
      "           | AUC Low-deg: 0.5009 | AUC High-deg: 0.9694\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 080 | Loss: 1.0502 | Val AUC: 0.8918 | Pos: 0.679 | Neg: 0.324\n",
      "           | AUC Low-deg: 0.4563 | AUC High-deg: 0.9700\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 085 | Loss: 1.0308 | Val AUC: 0.8987 | Pos: 0.734 | Neg: 0.329\n",
      "           | AUC Low-deg: 0.4700 | AUC High-deg: 0.9655\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 090 | Loss: 1.0253 | Val AUC: 0.9004 | Pos: 0.741 | Neg: 0.333\n",
      "           | AUC Low-deg: 0.4664 | AUC High-deg: 0.9663\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 095 | Loss: 1.0156 | Val AUC: 0.9032 | Pos: 0.724 | Neg: 0.318\n",
      "           | AUC Low-deg: 0.4625 | AUC High-deg: 0.9681\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 100 | Loss: 1.0122 | Val AUC: 0.9065 | Pos: 0.736 | Neg: 0.322\n",
      "           | AUC Low-deg: 0.4705 | AUC High-deg: 0.9717\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 105 | Loss: 1.0088 | Val AUC: 0.9079 | Pos: 0.760 | Neg: 0.342\n",
      "           | AUC Low-deg: 0.4724 | AUC High-deg: 0.9650\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 110 | Loss: 1.0089 | Val AUC: 0.9067 | Pos: 0.725 | Neg: 0.308\n",
      "           | AUC Low-deg: 0.4591 | AUC High-deg: 0.9705\n",
      "Epoch 115 | Loss: 1.0078 | Val AUC: 0.9100 | Pos: 0.753 | Neg: 0.340\n",
      "           | AUC Low-deg: 0.4739 | AUC High-deg: 0.9707\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 120 | Loss: 1.0046 | Val AUC: 0.9076 | Pos: 0.724 | Neg: 0.310\n",
      "           | AUC Low-deg: 0.4620 | AUC High-deg: 0.9675\n",
      "Epoch 125 | Loss: 1.0048 | Val AUC: 0.9107 | Pos: 0.751 | Neg: 0.339\n",
      "           | AUC Low-deg: 0.4715 | AUC High-deg: 0.9716\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 130 | Loss: 1.0018 | Val AUC: 0.9097 | Pos: 0.738 | Neg: 0.313\n",
      "           | AUC Low-deg: 0.4630 | AUC High-deg: 0.9710\n",
      "Epoch 135 | Loss: 1.0025 | Val AUC: 0.9112 | Pos: 0.750 | Neg: 0.335\n",
      "           | AUC Low-deg: 0.4747 | AUC High-deg: 0.9708\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 140 | Loss: 0.9977 | Val AUC: 0.9103 | Pos: 0.748 | Neg: 0.328\n",
      "           | AUC Low-deg: 0.4735 | AUC High-deg: 0.9685\n",
      "Epoch 145 | Loss: 0.9991 | Val AUC: 0.9102 | Pos: 0.727 | Neg: 0.318\n",
      "           | AUC Low-deg: 0.4699 | AUC High-deg: 0.9716\n",
      "Epoch 150 | Loss: 1.0062 | Val AUC: 0.9126 | Pos: 0.698 | Neg: 0.307\n",
      "           | AUC Low-deg: 0.4713 | AUC High-deg: 0.9683\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 155 | Loss: 1.0087 | Val AUC: 0.9121 | Pos: 0.739 | Neg: 0.353\n",
      "           | AUC Low-deg: 0.4667 | AUC High-deg: 0.9692\n",
      "Epoch 160 | Loss: 1.0052 | Val AUC: 0.9116 | Pos: 0.717 | Neg: 0.318\n",
      "           | AUC Low-deg: 0.4734 | AUC High-deg: 0.9675\n",
      "Epoch 165 | Loss: 1.0018 | Val AUC: 0.9118 | Pos: 0.735 | Neg: 0.339\n",
      "           | AUC Low-deg: 0.4707 | AUC High-deg: 0.9684\n",
      "Epoch 170 | Loss: 1.0007 | Val AUC: 0.9112 | Pos: 0.724 | Neg: 0.325\n",
      "           | AUC Low-deg: 0.4788 | AUC High-deg: 0.9669\n",
      "Epoch 175 | Loss: 1.0001 | Val AUC: 0.9113 | Pos: 0.734 | Neg: 0.333\n",
      "           | AUC Low-deg: 0.4724 | AUC High-deg: 0.9694\n",
      "Epoch 180 | Loss: 0.9994 | Val AUC: 0.9101 | Pos: 0.733 | Neg: 0.313\n",
      "           | AUC Low-deg: 0.4750 | AUC High-deg: 0.9716\n",
      "Epoch 185 | Loss: 0.9949 | Val AUC: 0.9124 | Pos: 0.745 | Neg: 0.314\n",
      "           | AUC Low-deg: 0.4881 | AUC High-deg: 0.9714\n",
      "Epoch 190 | Loss: 0.9984 | Val AUC: 0.9143 | Pos: 0.766 | Neg: 0.340\n",
      "           | AUC Low-deg: 0.4848 | AUC High-deg: 0.9684\n",
      "           | ‚úÖ Meilleur mod√®le sauvegard√©\n",
      "Epoch 195 | Loss: 0.9915 | Val AUC: 0.9109 | Pos: 0.749 | Neg: 0.326\n",
      "           | AUC Low-deg: 0.4753 | AUC High-deg: 0.9708\n",
      "Epoch 200 | Loss: 0.9910 | Val AUC: 0.9126 | Pos: 0.739 | Neg: 0.309\n",
      "           | AUC Low-deg: 0.4773 | AUC High-deg: 0.9619\n",
      "\n",
      "‚úÖ Entra√Ænement termin√©!\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ D√©but de l'entra√Ænement (anti-hub bias)...\\n\")\n",
    "\n",
    "best_val_auc = 0\n",
    "patience = 25\n",
    "patience_counter = 0\n",
    "history = {\n",
    "    'train_loss': [], \n",
    "    'val_auc': [], \n",
    "    'val_auc_low': [], \n",
    "    'val_auc_high': []\n",
    "}\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss, pos_mean, neg_mean = train_with_stratified_negatives()\n",
    "    history['train_loss'].append(loss)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        val_auc, val_acc, val_auc_low, val_auc_high = test_with_degree_analysis(val_data)\n",
    "        \n",
    "        history['val_auc'].append(val_auc)\n",
    "        history['val_auc_low'].append(val_auc_low if val_auc_low else 0)\n",
    "        history['val_auc_high'].append(val_auc_high if val_auc_high else 0)\n",
    "        \n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val AUC: {val_auc:.4f} | \"\n",
    "              f\"Pos: {pos_mean:.3f} | Neg: {neg_mean:.3f}\")\n",
    "        \n",
    "        if val_auc_low and val_auc_high:\n",
    "            print(f\"           | AUC Low-deg: {val_auc_low:.4f} | AUC High-deg: {val_auc_high:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            patience_counter = 0\n",
    "            \n",
    "            torch.save({\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'predictor': predictor.state_dict(),\n",
    "                'val_auc': val_auc,\n",
    "                'epoch': epoch\n",
    "            }, 'best_model.pt')\n",
    "            print(f\"           | ‚úÖ Meilleur mod√®le sauvegard√©\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n‚ö†Ô∏è Early stopping √† l'epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(\"\\n‚úÖ Entra√Ænement termin√©!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81d204c8-c30c-481a-9560-edd2a24e5fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä √âvaluation sur le set de test...\n",
      "\n",
      "============================================================\n",
      "R√âSULTATS FINAUX\n",
      "============================================================\n",
      "  Best Val AUC: 0.9143\n",
      "  Test AUC (global): 0.9123\n",
      "  Test Acc: 0.8498\n",
      "  Test AUC (low-degree): 0.4903\n",
      "  Test AUC (high-degree): 0.9686\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä √âvaluation sur le set de test...\\n\")\n",
    "\n",
    "# Charger meilleur mod√®le\n",
    "checkpoint = torch.load('best_model.pt')\n",
    "encoder.load_state_dict(checkpoint['encoder'])\n",
    "predictor.load_state_dict(checkpoint['predictor'])\n",
    "\n",
    "# Test final\n",
    "test_auc, test_acc, test_auc_low, test_auc_high = test_with_degree_analysis(test_data)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"R√âSULTATS FINAUX\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Best Val AUC: {best_val_auc:.4f}\")\n",
    "print(f\"  Test AUC (global): {test_auc:.4f}\")\n",
    "print(f\"  Test Acc: {test_acc:.4f}\")\n",
    "if test_auc_low:\n",
    "    print(f\"  Test AUC (low-degree): {test_auc_low:.4f}\")\n",
    "if test_auc_high:\n",
    "    print(f\"  Test AUC (high-degree): {test_auc_high:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc1c1133-8c56-4016-b950-64219f9ccc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ Diagnostic des embeddings...\n",
      "\n",
      "Similarit√© moyenne entre hubs: 0.6638\n",
      "‚úÖ Embeddings des hubs bien diff√©renci√©s\n",
      "\n",
      "Similarit√© moyenne (√©chantillon global): 0.5727\n",
      "√âcart-type des embeddings: 1.6200\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüî¨ Diagnostic des embeddings...\\n\")\n",
    "\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    final_embeddings = encoder(data.x.to(device), data.edge_index.to(device))\n",
    "\n",
    "# Analyser similarit√© des hubs\n",
    "hub_indices = extreme_hubs[:min(10, len(extreme_hubs))]\n",
    "hub_embeds = final_embeddings[hub_indices].cpu().numpy()\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "hub_sim = cosine_similarity(hub_embeds)\n",
    "np.fill_diagonal(hub_sim, 0)\n",
    "avg_hub_sim = hub_sim.mean()\n",
    "\n",
    "print(f\"Similarit√© moyenne entre hubs: {avg_hub_sim:.4f}\")\n",
    "if avg_hub_sim > 0.9:\n",
    "    print(f\"‚ö†Ô∏è Embeddings des hubs trop similaires (risque de biais)\")\n",
    "    print(f\"   ‚Üí Consid√©rer : plus de dropout, plus d'epochs, ou moins de hidden_channels\")\n",
    "else:\n",
    "    print(f\"‚úÖ Embeddings des hubs bien diff√©renci√©s\")\n",
    "\n",
    "# Analyser tous les embeddings\n",
    "all_embeds = final_embeddings.cpu().numpy()\n",
    "all_sim = cosine_similarity(all_embeds[:100])  # √âchantillon\n",
    "np.fill_diagonal(all_sim, 0)\n",
    "avg_all_sim = all_sim.mean()\n",
    "\n",
    "print(f\"\\nSimilarit√© moyenne (√©chantillon global): {avg_all_sim:.4f}\")\n",
    "print(f\"√âcart-type des embeddings: {all_embeds.std():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57dd4a56-b2ea-4b69-85f2-f15b3395a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Sauvegarde COMPL√àTE du mod√®le...\n",
      "\n",
      "‚úÖ Mod√®le sauvegard√©: ../results/link_prediction_model.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ Sauvegarde COMPL√àTE du mod√®le...\\n\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state': {\n",
    "        'encoder': encoder.state_dict(),\n",
    "        'predictor': predictor.state_dict()\n",
    "    },\n",
    "    'embeddings': final_embeddings.cpu(),\n",
    "    'node_to_idx': node_to_idx,\n",
    "    'metrics': {\n",
    "        'val_auc': best_val_auc,\n",
    "        'test_auc': test_auc,\n",
    "        'test_acc': test_acc,\n",
    "        'test_auc_low': test_auc_low if test_auc_low else 0,\n",
    "        'test_auc_high': test_auc_high if test_auc_high else 0\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'in_channels': train_data.x.size(1),\n",
    "        'hidden_channels': 128,\n",
    "        'embedding_dim': 64,\n",
    "        'dropout': 0.5\n",
    "    },\n",
    "    'degree_stats': {\n",
    "        'p50': float(degree_p50),\n",
    "        'p90': float(degree_p90),\n",
    "        'p95': float(degree_p95),\n",
    "        'max': float(degrees_array.max())\n",
    "    },\n",
    "    'metadata': {\n",
    "        'num_nodes': len(node_to_idx),\n",
    "        'num_edges': data.edge_index.shape[1],\n",
    "        'training_date': str(pd.Timestamp.now()),\n",
    "        'device': str(device),\n",
    "        'hub_embedding_similarity': float(avg_hub_sim),\n",
    "        'global_embedding_similarity': float(avg_all_sim),\n",
    "        'training_method': 'stratified_negative_sampling_v2'\n",
    "    }\n",
    "}, MODEL_OUTPUT)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le sauvegard√©: {MODEL_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a7e5f2-d4b3-47ef-bb46-5cdd65f570aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ V√©rification du fichier sauvegard√©...\n",
      "\n",
      "‚úÖ Fichier valide:\n",
      "   Embeddings: torch.Size([10363, 64])\n",
      "   N≈ìuds: 10363\n",
      "   Test AUC: 0.9123\n",
      "   Hub similarity: 0.6638\n",
      "   Training method: stratified_negative_sampling_v2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüß™ V√©rification du fichier sauvegard√©...\\n\")\n",
    "\n",
    "test_checkpoint = torch.load(MODEL_OUTPUT, map_location='cpu', weights_only=False)\n",
    "\n",
    "print(f\"‚úÖ Fichier valide:\")\n",
    "print(f\"   Embeddings: {test_checkpoint['embeddings'].shape}\")\n",
    "print(f\"   N≈ìuds: {len(test_checkpoint['node_to_idx'])}\")\n",
    "print(f\"   Test AUC: {test_checkpoint['metrics']['test_auc']:.4f}\")\n",
    "print(f\"   Hub similarity: {test_checkpoint['metadata']['hub_embedding_similarity']:.4f}\")\n",
    "print(f\"   Training method: {test_checkpoint['metadata']['training_method']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c733ee3-111e-4b89-9970-6baf8380e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test de pr√©dictions sur quelques exemples...\n",
      "\n",
      "Chercheur test: 2064770039 (degree: 35)\n",
      "\n",
      "Top 5 scores:\n",
      "  1. Candidat 48650879 (degree: 128) ‚Üí score: 0.4601\n",
      "  2. Candidat 2046135 (degree: 9) ‚Üí score: 0.3702\n",
      "  3. Candidat 1700880 (degree: 9) ‚Üí score: 0.2607\n",
      "  4. Candidat 39393520 (degree: 12) ‚Üí score: 0.2534\n",
      "  5. Candidat 2302053110 (degree: 7) ‚Üí score: 0.1980\n",
      "\n",
      "‚úÖ Test de pr√©diction OK\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüß™ Test de pr√©dictions sur quelques exemples...\\n\")\n",
    "\n",
    "# Prendre un chercheur al√©atoire\n",
    "test_author_idx = np.random.choice(len(node_list))\n",
    "test_author_id = node_list[test_author_idx]\n",
    "\n",
    "print(f\"Chercheur test: {test_author_id} (degree: {node_degrees[test_author_id]})\")\n",
    "\n",
    "# Prendre 10 candidats al√©atoires\n",
    "candidate_indices = np.random.choice(len(node_list), 10, replace=False)\n",
    "\n",
    "# Pr√©dire\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    z = encoder(data.x.to(device), data.edge_index.to(device))\n",
    "    \n",
    "    edge_index = torch.tensor([\n",
    "        [test_author_idx] * 10,\n",
    "        candidate_indices.tolist()\n",
    "    ], dtype=torch.long, device=device)\n",
    "    \n",
    "    scores = predictor(z, edge_index).cpu().numpy()\n",
    "\n",
    "print(f\"\\nTop 5 scores:\")\n",
    "top_5_idx = np.argsort(scores)[-5:][::-1]\n",
    "for rank, idx in enumerate(top_5_idx, 1):\n",
    "    cand_id = node_list[candidate_indices[idx]]\n",
    "    cand_deg = node_degrees[cand_id]\n",
    "    print(f\"  {rank}. Candidat {cand_id} (degree: {cand_deg}) ‚Üí score: {scores[idx]:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Test de pr√©diction OK\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4ccf4cf-f0ec-4c95-8450-3f036aab79e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Cr√©ation d'exemples pour tests API...\n",
      "\n",
      "‚úÖ Exemples sauvegard√©s: ../results/example_researchers.json\n",
      "\n",
      "Top 5 chercheurs pour tester:\n",
      "   1. 46617804 (568 collaborations)\n",
      "   2. 39589154 (535 collaborations)\n",
      "   3. 1727524 (531 collaborations)\n",
      "   4. 2010057 (528 collaborations)\n",
      "   5. 2322150 (525 collaborations)\n",
      "\n",
      "============================================================\n",
      "‚úÖ PR√äT POUR L'API!\n",
      "============================================================\n",
      "\n",
      "Fichiers cr√©√©s:\n",
      "   ../results/link_prediction_model.pt\n",
      "   ../results/communities/louvain_partition.pkl\n",
      "   ../results/example_researchers.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìã Cr√©ation d'exemples pour tests API...\\n\")\n",
    "\n",
    "# Top chercheurs par degr√©\n",
    "top_by_degree = sorted(node_degrees.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# √âchantillon al√©atoire\n",
    "random_sample = np.random.choice(node_list, min(10, len(node_list)), replace=False)\n",
    "\n",
    "example_nodes = {\n",
    "    'top_connected': [str(node) for node, deg in top_by_degree[:10]],\n",
    "    'random_sample': [str(node) for node in random_sample],\n",
    "    'low_degree': [str(node) for node in node_list if node_degrees[node] < degree_p50][:10],\n",
    "    'mid_degree': [str(node) for node in node_list if degree_p50 < node_degrees[node] < degree_p90][:10]\n",
    "}\n",
    "\n",
    "examples_path = \"../results/example_researchers.json\"\n",
    "import json\n",
    "with open(examples_path, 'w') as f:\n",
    "    json.dump(example_nodes, indent=2, fp=f)\n",
    "\n",
    "print(f\"‚úÖ Exemples sauvegard√©s: {examples_path}\")\n",
    "print(f\"\\nTop 5 chercheurs pour tester:\")\n",
    "for i, (node, deg) in enumerate(top_by_degree[:5], 1):\n",
    "    print(f\"   {i}. {node} ({deg} collaborations)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ PR√äT POUR L'API!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nFichiers cr√©√©s:\")\n",
    "print(f\"   {MODEL_OUTPUT}\")\n",
    "print(f\"   {PARTITION_PATH}\")\n",
    "print(f\"   {examples_path}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fdce12-fd42-4d59-a4ab-38c5515d220f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
