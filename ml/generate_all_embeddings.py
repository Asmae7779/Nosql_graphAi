import torch
import networkx as nx
import numpy as np
from torch_geometric.nn import SAGEConv
import torch.nn as nn
import torch.nn.functional as F
import pickle
from neo4j import GraphDatabase
import os

# ========== CLASSES DU MODÃˆLE ==========
class GraphSAGE(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):
        super().__init__()
        self.conv1 = SAGEConv(in_channels, hidden_channels)
        self.conv2 = SAGEConv(hidden_channels, out_channels)
        self.dropout = dropout
    
    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.conv2(x, edge_index)
        return x

class EdgePredictor(nn.Module):
    def __init__(self, embedding_dim):
        super().__init__()
        self.lin = nn.Linear(embedding_dim * 2, 1)
    
    def forward(self, z, edge_index):
        src = z[edge_index[0]]
        dst = z[edge_index[1]]
        out = torch.cat([src, dst], dim=1)
        return torch.sigmoid(self.lin(out)).squeeze()

# ========== FONCTIONS D'AIDE ==========
def load_complete_graph_from_neo4j():
    """Charger TOUS les auteurs depuis Neo4j"""
    
    # Tes credentials Neo4j Aura
    NEO4J_URI = "neo4j+s://c0d3b4ca.databases.neo4j.io"
    NEO4J_USER = "neo4j"
    NEO4J_PASSWORD = "a7Pxd2CxrqsYpXhWsmb7kFpTX9Wnw8ofB-2WNkzfUZk"
    
    driver = GraphDatabase.driver(
        NEO4J_URI,
        auth=(NEO4J_USER, NEO4J_PASSWORD)
    )
    
    G = nx.Graph()
    
    print("ğŸ“¥ Connexion Ã  Neo4j pour charger le graphe complet...")
    
    try:
        with driver.session() as session:
            # âœ… Charger tous les auteurs
            print("ğŸ“¥ Chargement des auteurs...")
            result = session.run("""
                MATCH (a:authors)
                WHERE a.authorId IS NOT NULL
                RETURN a.authorId AS id, a.name AS name
            """)
            
            author_count = 0
            for record in result:
                author_id = record["id"]
                if author_id:
                    G.add_node(author_id, name=record["name"])
                    author_count += 1
            
            print(f"âœ… {author_count} auteurs chargÃ©s")
            
            # âœ… Charger toutes les collaborations
            print("ğŸ“¥ Chargement des collaborations...")
            result = session.run("""
                MATCH (a1:authors)-[:AUTHORED]->(p:papers)<-[:AUTHORED]-(a2:authors)
                WHERE a1.authorId IS NOT NULL AND a2.authorId IS NOT NULL 
                    AND a1.authorId < a2.authorId
                RETURN a1.authorId AS src, a2.authorId AS dst
            """)
            
            edge_count = 0
            for record in result:
                src = record["src"]
                dst = record["dst"]
                if src and dst and G.has_node(src) and G.has_node(dst):
                    G.add_edge(src, dst)
                    edge_count += 1
            
            print(f"âœ… {edge_count} collaborations chargÃ©es")
    
    except Exception as e:
        print(f"âŒ Erreur lors du chargement depuis Neo4j: {e}")
        raise e
    
    finally:
        driver.close()
    
    # Statistiques
    isolated = list(nx.isolates(G))
    print(f"â„¹ï¸  {len(isolated)} auteurs isolÃ©s (sans collaborations)")
    print(f"ğŸ“Š Graphe: {G.number_of_nodes()} nÅ“uds, {G.number_of_edges()} arÃªtes")
    
    return G

def compute_louvain_communities(G):
    """Calculer les communautÃ©s avec l'algorithme de Louvain"""
    print("ğŸ” Calcul des communautÃ©s avec Louvain...")
    try:
        import community as community_louvain
        partition = community_louvain.best_partition(G)
        print(f"âœ… {len(set(partition.values()))} communautÃ©s dÃ©tectÃ©es")
        return partition
    except Exception as e:
        print(f"âš ï¸  Erreur calcul communautÃ©s: {e}")
        # Partition par dÃ©faut (tous dans la mÃªme communautÃ©)
        return {node: 0 for node in G.nodes()}

def compute_global_metrics(G, partition):
    """Calculer toutes les mÃ©triques pour le graphe"""
    print("ğŸ“Š Calcul des mÃ©triques globales...")
    
    metrics_cache = {}
    
    # DegrÃ©
    print("  â†’ DegrÃ©")
    degrees = dict(G.degree())
    
    # CentralitÃ© de degrÃ©
    print("  â†’ CentralitÃ© de degrÃ©")
    degree_cent = nx.degree_centrality(G)
    
    # PageRank (version simplifiÃ©e pour grand graphe)
    print("  â†’ PageRank")
    try:
        if G.number_of_nodes() > 10000:
            pagerank = nx.pagerank(G, max_iter=20)
        else:
            pagerank = nx.pagerank(G, max_iter=50)
    except:
        # Fallback simple
        pagerank = {node: 1.0/G.number_of_nodes() for node in G.nodes()}
    
    # Clustering coefficient
    print("  â†’ Coefficient de clustering")
    try:
        clustering = nx.clustering(G)
    except:
        clustering = {node: 0.0 for node in G.nodes()}
    
    # Stocker dans le cache
    for node in G.nodes():
        metrics_cache[node] = {
            'degree': degrees.get(node, 0),
            'degree_centrality': degree_cent.get(node, 0),
            'pagerank': pagerank.get(node, 0),
            'clustering_coefficient': clustering.get(node, 0),
            'community': partition.get(node, -1)
        }
    
    print(f"âœ… {len(metrics_cache)} mÃ©triques calculÃ©es")
    return metrics_cache

# ========== FONCTION PRINCIPALE ==========
def main():
    print("=" * 60)
    print("ğŸ¯ GÃ‰NÃ‰RATION DES EMBEDDINGS POUR TOUS LES AUTEURS")
    print("=" * 60)
    
    # 1. Charger le graphe complet depuis Neo4j
    print("\n1ï¸âƒ£ Chargement du graphe depuis Neo4j...")
    G_full = load_complete_graph_from_neo4j()
    
    # Sauvegarder le graphe pour rÃ©fÃ©rence
    with open("data/graph_complete.pkl", "wb") as f:
        pickle.dump(G_full, f)
    print("ğŸ’¾ Graphe complet sauvegardÃ© dans data/graph_complete.pkl")
    
    # 2. CrÃ©er node_to_idx pour tous les auteurs
    print("\n2ï¸âƒ£ CrÃ©ation des mappings...")
    node_list = list(G_full.nodes())
    node_to_idx = {node: idx for idx, node in enumerate(node_list)}
    idx_to_node = {v: k for k, v in node_to_idx.items()}
    
    print(f"âœ… {len(node_to_idx)} auteurs dans le mapping")
    
    # 3. Calculer les communautÃ©s
    print("\n3ï¸âƒ£ Calcul des communautÃ©s...")
    partition = compute_louvain_communities(G_full)
    
    # 4. Calculer les mÃ©triques
    print("\n4ï¸âƒ£ Calcul des mÃ©triques...")
    metrics_cache = compute_global_metrics(G_full, partition)
    
    # Sauvegarder le cache de mÃ©triques
    with open("results/metrics_cache_complete.pkl", "wb") as f:
        pickle.dump(metrics_cache, f)
    print("ğŸ’¾ Cache de mÃ©triques sauvegardÃ©")
    
    # 5. Charger le modÃ¨le prÃ©-entraÃ®nÃ©
    print("\n5ï¸âƒ£ Chargement du modÃ¨le prÃ©-entraÃ®nÃ©...")
    
    # VÃ©rifier si le modÃ¨le existe
    model_path = "models/link_prediction_model.pkl"
    if not os.path.exists(model_path):
        print("âŒ ModÃ¨le non trouvÃ©. ExÃ©cute d'abord l'entraÃ®nement.")
        return
    
    checkpoint = torch.load(model_path, map_location="cpu", weights_only=False)
    
    # 6. GÃ©nÃ©rer les features
    print("\n6ï¸âƒ£ GÃ©nÃ©ration des features...")
    
    # Features simplifiÃ©es: [degree, pagerank, clustering]
    features_list = []
    for node in node_list:
        metrics = metrics_cache.get(node, {})
        features = [
            metrics.get('degree', 0),
            metrics.get('pagerank', 0),
            metrics.get('clustering_coefficient', 0)
        ]
        features_list.append(features)
    
    x = torch.tensor(features_list, dtype=torch.float)
    print(f"âœ… Features: {x.shape}")
    
    # 7. CrÃ©er edge_index
    print("\n7ï¸âƒ£ CrÃ©ation des arÃªtes...")
    edges = []
    for u, v in G_full.edges():
        if u in node_to_idx and v in node_to_idx:
            edges.append((node_to_idx[u], node_to_idx[v]))
    
    if edges:
        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        print(f"âœ… Edge index: {edge_index.shape}")
    else:
        edge_index = torch.tensor([[], []], dtype=torch.long)
        print("âš ï¸  Aucune arÃªte trouvÃ©e")
    
    # 8. Initialiser l'encodeur
    print("\n8ï¸âƒ£ Initialisation du modÃ¨le...")
    embedding_dim = 64
    encoder = GraphSAGE(3, 128, embedding_dim)
    
    # Charger les poids si disponibles
    if 'model_state' in checkpoint:
        encoder.load_state_dict(checkpoint['model_state']['encoder'])
        print("âœ… Poids de l'encodeur chargÃ©s")
    else:
        print("âš ï¸  Poids non trouvÃ©s, initialisation alÃ©atoire")
    
    encoder.eval()
    
    # 9. GÃ©nÃ©rer les embeddings
    print("\n9ï¸âƒ£ GÃ©nÃ©ration des embeddings...")
    with torch.no_grad():
        if edge_index.shape[1] > 0:
            embeddings = encoder(x, edge_index)
        else:
            # Si pas d'arÃªtes, utiliser features comme embeddings
            embeddings = x
    
    print(f"âœ… Embeddings: {embeddings.shape}")
    
    # 10. CrÃ©er le modÃ¨le Ã©tendu
    print("\nğŸ”Ÿ CrÃ©ation du modÃ¨le Ã©tendu...")
    extended_model = {
        'embeddings': embeddings,
        'node_to_idx': node_to_idx,
        'idx_to_node': idx_to_node,
        'G_full': G_full,
        'partition': partition,
        'metrics_cache': metrics_cache,
        'model_state': checkpoint.get('model_state', {})
    }
    
    # 11. Sauvegarder le modÃ¨le Ã©tendu
    output_path = "models/link_prediction_model_extended.pkl"
    torch.save(extended_model, output_path)
    
    print("=" * 60)
    print("âœ… MODÃˆLE Ã‰TENDU GÃ‰NÃ‰RÃ‰ AVEC SUCCÃˆS")
    print("=" * 60)
    print(f"ğŸ“ Fichier: {output_path}")
    print(f"ğŸ‘¥ Auteurs: {len(node_to_idx)}")
    print(f"ğŸ¤ ArÃªtes: {len(edges)}")
    print(f"ğŸ¢ CommunautÃ©s: {len(set(partition.values()))}")
    print(f"ğŸ“Š Embeddings: {embeddings.shape}")
    print("=" * 60)

if __name__ == "__main__":
    main()